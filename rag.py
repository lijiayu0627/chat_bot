import os

import openai
from openai import OpenAI
import json


class RAGSystem:
    """
        Retrieval-Augmented Generation (RAG) system that combines
        semantic search from product and FAQ databases with GPT model responses.
    """
    def __init__(self, faq_database, product_database, api_key):
        """
              Initializes the RAG system.

              Args:
                  faq_database (ServiceDatabase): FAQ database instance.
                  product_database (ProductDatabase): Product database instance.
        """
        self.faq_database = faq_database
        self.product_database = product_database
        self.message_history = []
        self.client = OpenAI(api_key=api_key)
        self.model = 'gpt-4o-mini-2024-07-18'
        if os.path.exists('fine_tuned_model_id.json'):
            with open('fine_tuned_model_id.json', 'r') as fp:
                self.model = json.load(fp)

    def retrieve_context(self, query):
        """
        Retrieves relevant context from databases based on the query.

        Args:
            query (str): User's query string.
            initial (bool): Indicates if it's the first query in the conversation.

        Returns:
            str: Retrieved context as a single combined string.
        """

        similar_product, _ = self.product_database.search(query, top_k=10)
        similar_qas, _ = self.faq_database.search(query, top_k=3)
        product_context = "\n\n".join(similar_product)
        qa_context = "\n\n".join(similar_qas)

        return product_context,qa_context

    def generate_answer(self, query, product_context, qa_context, initial):
        """
        Generates an answer using GPT model based on the query and context.

        Args:
            query (str): User's query string.
            context (str): Retrieved context from the databases.
            initial (bool): Indicates if it's the first query in the conversation.

        Returns:
            str: Generated response from the GPT model.
        """
        if initial:
            self.message_history.append({
                "role": "system",
                "content": (
                    "You are a helpful assistant for an e-commerce platform. "
                    "For the product related queries such as product category, price and delivery, please check current and previous Product Context."
                    "For the operation related queries such as payment and refund, please check current FAQ Context."
                    "Use context and chat history to answer questions very concisely."
                    "Please do not include irrelated information."
                    "If the query includes pronouns like 'it', reference previous query and answer."
                )
            })

        self.message_history.append({"role": "system","content": f"Product Context: {product_context}"})
        self.message_history.append({"role": "system", "content": f"FAQ Context: {qa_context}"})
        self.message_history.append({"role": "user", "content": query})

        response = self.client.chat.completions.create(
            model=self.model,
            messages=self.message_history
        )

        assistant_reply = response.choices[0].message.content
        self.message_history.append({"role": "assistant", "content": assistant_reply})
        return assistant_reply

    def ask(self, query, initial):
        """
        Handles user queries by retrieving context and generating responses.

        Args:
            query (str): User's query string.
            initial (bool): Indicates if it's the first query in the conversation.

        Returns:
            str: Response generated by the RAG system.
        """
        product_context, qa_context = self.retrieve_context(query)
        return self.generate_answer(query, product_context, qa_context, initial)