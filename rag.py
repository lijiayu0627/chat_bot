import os

import openai
from openai import OpenAI
import json


class RAGSystem:
    """
        Retrieval-Augmented Generation (RAG) system that combines
        semantic search from product and FAQ databases with GPT model responses.
    """
    def __init__(self, service_database, product_database, api_key):
        """
              Initializes the RAG system.

              Args:
                  service_database (ServiceDatabase): FAQ database instance.
                  product_database (ProductDatabase): Product database instance.
        """
        self.service_database = service_database
        self.product_database = product_database
        self.message_history = []
        self.client = OpenAI(api_key=api_key)
        self.model = 'gpt-4o-mini-2024-07-18'
        if os.path.exists('fine_tuned_model_id.json'):
            with open('fine_tuned_model_id.json', 'r') as fp:
                self.model = json.load(fp)

    def retrieve_context(self, query, initial):
        """
        Retrieves relevant context from databases based on the query.

        Args:
            query (str): User's query string.
            initial (bool): Indicates if it's the first query in the conversation.

        Returns:
            str: Retrieved context as a single combined string.
        """
        if initial:
            similar_knowledges, _ = self.product_database.search(query, top_k=10)
            similar_qas, _ = self.service_database.search(query, top_k=3)
            context = "\n\n".join(similar_knowledges + similar_qas)
        else:
            similar_qas, _ = self.service_database.search(query, top_k=3)
            context = "\n\n".join(similar_qas)

        return context

    def generate_answer(self, query, context, initial):
        """
        Generates an answer using GPT model based on the query and context.

        Args:
            query (str): User's query string.
            context (str): Retrieved context from the databases.
            initial (bool): Indicates if it's the first query in the conversation.

        Returns:
            str: Generated response from the GPT model.
        """
        if initial:
            self.message_history.append({
                "role": "system",
                "content": (
                    "You are a helpful assistant for an e-commerce platform. "
                    "Use context and chat history to answer questions concisely. "
                    "If the query includes pronouns like 'it', reference previous dialogue."
                )
            })

        prompt = f"""
Context:
{context}

Question:
{query}

Answer:"""
        self.message_history.append({"role": "user", "content": prompt})

        response = self.client.chat.completions.create(
            model=self.model,
            messages=self.message_history
        )

        assistant_reply = response.choices[0].message.content
        self.message_history.append({"role": "assistant", "content": assistant_reply})
        return assistant_reply

    def ask(self, query, initial):
        """
        Handles user queries by retrieving context and generating responses.

        Args:
            query (str): User's query string.
            initial (bool): Indicates if it's the first query in the conversation.

        Returns:
            str: Response generated by the RAG system.
        """
        context = self.retrieve_context(query, initial)
        return self.generate_answer(query, context, initial)


